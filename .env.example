# ==================== LLM Configuration ====================
# Choose provider: 'ollama' or 'openai'
LLM_PROVIDER=ollama

# For OpenAI (if using OpenAI)
OPENAI_API_KEY=your_openai_api_key_here

# Ollama settings
LLM_MODEL=phi4-mini
EMBEDDING_MODEL=nomic-embed-text
OLLAMA_BASE_URL=http://localhost:11434

# ==================== Server Configuration ====================
HOST=0.0.0.0
PORT=8000
DEBUG=false

# ==================== Security ====================
# Rate limiting (requests per window)
RATE_LIMIT_REQUESTS=60
RATE_LIMIT_WINDOW=60

# Max message length
MAX_CONTENT_LENGTH=10000

# ==================== Telegram Bot (Optional) ====================
TELEGRAM_ENABLED=false
TELEGRAM_BOT_TOKEN=your_telegram_bot_token
TELEGRAM_CHAT_ID=your_chat_id

# ==================== Discord Webhook (Optional) ====================
DISCORD_ENABLED=false
DISCORD_WEBHOOK_URL=your_discord_webhook_url
